{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le data mining vs le machine learning\n",
    "\n",
    "- Data Mining : recherche d’information et de patterns cachés dans une base de données isolée ou en croisant plusieurs bases. C’est l’être humain qui explore et prend des décisions.\n",
    "- Le data mining s’appuie sur des techniques et algorithmes issus de la statistique et de la gestion de bases de données.\n",
    "- Les données exploitées ont souvent une taille considérable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Quelques exemples\n",
    "\n",
    "- Prestation de service : identification des paramètres de prédisposition à la résiliation (churn)\n",
    "- Marketing: identification de segments distincts de consommateurs \n",
    "- Production : identification de paramètres induisant des défaillances\n",
    "- Pharmaceutique: classification de médicaments selon le profil chimique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Le machine learning\n",
    "\n",
    "- Machine Learning : Techniques de calcul permettant aux ordinateurs d’apprendre à exécuter des tâches en s’inspirant de patterns perçus sur des données, avec peu d’intervention humaine. Les tâches se résument souvent à de la prédiction.\n",
    "\n",
    "![image](./images/ml1.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](./images/trend-ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les outils\n",
    "\n",
    "![image](./images/poll-ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les types de machine learning\n",
    "\n",
    "- Les algorithmes de machine learning peuvent être rassemblés dans 3 groupes principaux :\n",
    "   - L'apprentissage supervisé\n",
    "   - Cible (variable dépendante qualitative ou quantitative)\n",
    "   - Prédicteurs (variables indépendantes)\n",
    "   - Régression, arbre de decision, foret aléatoire, kNN, regression logistique, SVM…\n",
    "\n",
    "- L'apprentissage non supervisé\n",
    "    - Pas de variable dépendante, pas de modélisation\n",
    "    - Classer des individus dans différents groups ou trouver des associations\n",
    "    - Apriori algorithm, K-means.\n",
    "\n",
    "- L'apprentissage par renforcement\n",
    "    - Apprentissage pour prendre des décisions spécifique afin d’aboutir à un but précis\n",
    "    - Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L’analyse de données et le machine learning avec Python\n",
    "\n",
    "Le package la plus adaptée pour faire du data mining et du machine learning est la package **scikit-learn**\n",
    "\n",
    "\n",
    "Ce package propose des fonctions prédéfinies pour un grand nombre de méthodes\n",
    "\n",
    "- La classification : SVM, plus proches voisins, random forest…\n",
    "- Les régressions : linéaire, ridge, Lasso…\n",
    "- Le clustering : k-means…\n",
    "- L’analyse de données :  ACP, DA…\n",
    "\n",
    "Dans le cadre de cette formation, l'objectf n'est pas de décrire la théorie des méthodes mais plutôt de comprendre l'utilisation de Python pour les appliquer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L’apprentissage supervisé avec Scikit-Learn\n",
    "Les méthodes d’apprentissage supervisé sont les méthodes actuellement les plus\n",
    "utilisées en data science. Il s’agit d’essayer de prédire une variable cible et d’utiliser\n",
    "différentes méthodes pour arriver à cette fin.\n",
    "Nous allons illustrer ces méthodes de traitement de données avec du code et des\n",
    "cas pratiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Les données et leur transformation\n",
    "Ce jeu de données est décrit en détail au début du chapitre 4. Pour rappel, il est composé de 3333 individus et de 18 variables. Il est stocké dans un fichier csv, nommé telecom.csv, accessible dans le répertoire Data. On le récupère en utilisant Pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "churn=pd.read_csv(\"./data/telecom.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Les données\n",
    "\n",
    "Ce jeu de données n’a pas de données manquantes et nous allons devoir effectuer\n",
    "quelques transformations pour l’adapter à nos traitements. Nous voyons par exemple qu’il est composé de trois colonnes object.\n",
    "\n",
    "Nous pouvons afficher les statistiques descriptives pour les colonnes object :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>3333</td>\n",
       "      <td>51</td>\n",
       "      <td>WV</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <td>3333</td>\n",
       "      <td>3333</td>\n",
       "      <td>339-5659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Int'l Plan</th>\n",
       "      <td>3333</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VMail Plan</th>\n",
       "      <td>3333</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn?</th>\n",
       "      <td>3333</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count unique       top  freq\n",
       "State       3333     51        WV   106\n",
       "Phone       3333   3333  339-5659     1\n",
       "Int'l Plan  3333      2        no  3010\n",
       "VMail Plan  3333      2        no  2411\n",
       "Churn?      3333      2    False.  2850"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.describe(include=\"object\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformation des données\n",
    "\n",
    "On voit que les données sont toutes binaires. \n",
    "\n",
    "Pour les variables binaires, il nous suffit de les recoder avec Scikit-Learn pour obtenir des données exploitables. Par\n",
    "ailleurs, il existe une autre variable qualitative dans notre jeu de données, Area Code,\n",
    "qui est numérique mais avec trois modalités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415    1655\n",
       "510     840\n",
       "408     838\n",
       "Name: Area Code, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn[\"Area Code\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La préparation des données\n",
    "\n",
    "Nous allons utiliser le processus de traitement classique pour transformer nos\n",
    "données avec Scikit-Learn. Dans ce cas, nous n’avons pas de données manquantes,\n",
    "nous travaillons donc sur la transformation des variables qualitatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,Imputer\n",
    "#from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "LabelEncoder va nous permettre de transformer les valeurs textuelles en entiers.\n",
    "Nous pouvons utiliser pour chaque variable qualitative :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# création d'un objet\n",
    "encoder=LabelEncoder()\n",
    "# on applique les données à l'objet\n",
    "churn[\"Churn?\"]=encoder.fit_transform(churn[\"Churn?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2850\n",
       "1     483\n",
       "Name: Churn?, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn[\"Churn?\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False.', 'False.', 'False.', ..., 'False.', 'False.', 'False.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(churn[\"Churn?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def fonc_transfo(frame):\n",
    "    \"\"\" Fonction permettant de transformer toutes les colonnes qualitatives en quanti\n",
    "    et de stocker les objets dans un dictionnaie\n",
    "    \"\"\"\n",
    "    dict_label_encode={}\n",
    "    for col in frame.columns:\n",
    "        if frame[col].dtype == object:\n",
    "            dict_label_encode[col]=LabelEncoder()\n",
    "            frame[col]=dict_label_encode[col].fit_transform(frame[col])\n",
    "    \n",
    "    return frame, dict_label_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn, dico_label = fonc_transfo(churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>1926</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>1575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>1117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>1707</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  Account Length  Area Code  Phone  Int'l Plan  VMail Plan  \\\n",
       "0     16             128        415   1926           0           1   \n",
       "1     35             107        415   1575           0           1   \n",
       "2     31             137        415   1117           0           0   \n",
       "3     35              84        408   1707           1           0   \n",
       "4     36              75        415    110           1           0   \n",
       "\n",
       "   VMail Message  Day Mins  Day Calls  Day Charge  ...  Eve Calls  Eve Charge  \\\n",
       "0             25     265.1        110       45.07  ...         99       16.78   \n",
       "1             26     161.6        123       27.47  ...        103       16.62   \n",
       "2              0     243.4        114       41.38  ...        110       10.30   \n",
       "3              0     299.4         71       50.90  ...         88        5.26   \n",
       "4              0     166.7        113       28.34  ...        122       12.61   \n",
       "\n",
       "   Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "0       244.7           91         11.01       10.0           3         2.70   \n",
       "1       254.4          103         11.45       13.7           3         3.70   \n",
       "2       162.6          104          7.32       12.2           5         3.29   \n",
       "3       196.9           89          8.86        6.6           7         1.78   \n",
       "4       186.9          121          8.41       10.1           3         2.73   \n",
       "\n",
       "   CustServ Calls  Churn?  \n",
       "0               1       0  \n",
       "1               1       0  \n",
       "2               0       0  \n",
       "3               2       0  \n",
       "4               3       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prédire l’attrition des clients\n",
    "Lorsqu’on veut prédire une variable binaire, on devra avoir une colonne du type\n",
    "binaire. On préfère généralement un codage 0/1 afin de garder un type entier simple à gérer. \n",
    "\n",
    "Les variables explicatives x auront été préparées de manière intelligente afin de bien appliquer nos modèles.\n",
    "\n",
    "On crée donc x et y :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = churn[\"Churn?\"]\n",
    "x= churn.select_dtypes(np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Séparation des données\n",
    "\n",
    "Pour la séparation, on utilise la fonction train_test_split() de Scikit-Learn.\n",
    "\n",
    "Cette fonction permet de créer automatiquement autant de structures que nécessaire\n",
    "à partir de nos données. \n",
    "\n",
    "Elle utilise une randomisation des individus et ensuite une séparation en fonction d’un paramètre du type test_size :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# on importe la fonction\n",
    "from sklearn.model_selection import train_test_split\n",
    "# dans ce cas on a :\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dans certains cas, il peut arriver qu’il y ait une forte disparité de distribution des\n",
    "modalités entre les proportions d’acceptation et de refus. On peut vouloir faire en\n",
    "sorte que les répartitions des modalités de y soient égales dans les différents échantillons,\n",
    "on pourra alors utiliser une stratification. On va utiliser une stratification en\n",
    "prenant y comme base pour effectuer la stratification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.855086\n",
       "1    0.144914\n",
       "Name: Churn?, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,stratify = y)\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ainsi les deux échantillons _train et _test ont la même distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.855\n",
       "1    0.145\n",
       "Name: Churn?, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.855122\n",
       "1    0.144878\n",
       "Name: Churn?, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Le choix et l’ajustement de l’algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout au long de ce Notebook, nous allons essayer d'ajouter un nouveau modèle, il s'agit du modèle GBM\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ensuite, on crée un objet à partir de la classe du modèle en lui fournissant les\n",
    "hyperparamètres dont il a besoin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "modele_rf=RandomForestClassifier(n_estimators=100,)\n",
    "modele_knn=KNeighborsClassifier(n_neighbors=5)\n",
    "modele_nb=GaussianNB()\n",
    "modele_gbm=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dans ce cas, on prend les hyperparamètres par défaut.\n",
    "\n",
    "On peut ensuite ajuster notre modèle en utilisant les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 422 ms\n",
      "Wall time: 13 ms\n",
      "Wall time: 5.98 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%time modele_rf.fit(x_train,y_train)\n",
    "%time modele_knn.fit(x_train,y_train)\n",
    "%time modele_nb.fit(x_train,y_train)\n",
    "%time modele_gbm.fit(x_train,y_train)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une fois qu’on a estimé les paramètres du modèle, on va pouvoir extraire des\n",
    "informations. De nouveaux attributs de chaque classe apparaissent, ils se terminent par le symbole underscore _ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0053081 , 0.00559181, 0.00129665, 0.00480875, 0.03894956,\n",
       "       0.00625659, 0.01101723, 0.04470434, 0.00733399, 0.04343462,\n",
       "       0.01594849, 0.00532705, 0.0147657 , 0.00663377, 0.00471147,\n",
       "       0.00876722, 0.01077326, 0.01460163, 0.01279262, 0.03567387,\n",
       "       0.70130328])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ce qui va nous intéresse avant tout, c’est de prédire avec notre modèle. Pour cela nous allons utiliser la méthode .predict() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28 ms\n",
      "Wall time: 72.8 ms\n",
      "Wall time: 14.1 ms\n",
      "Wall time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_predict_rf = modele_rf.predict(x_test)\n",
    "%time y_predict_knn = modele_knn.predict(x_test)\n",
    "%time y_predict_nb = modele_nb.predict(x_test)\n",
    "%time y_predict_gbm = modele_gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On obtient ainsi une valeur prédite pour les éléments de notre échantillon de\n",
    "validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les indicateurs pour valider un modèle\n",
    "La partie validation d’un modèle d’apprentissage supervisé est extrêmement\n",
    "importante. L’objectif d’un modèle d’apprentissage supervisé est de prédire une\n",
    "valeur la plus proche possible de la réalité. Nous différencions trois types d’indices\n",
    "en fonction du type de variable cible. Tous les indicateurs de qualité du modèle sont\n",
    "stockés dans le module *metrics* de Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Le pourcentage de bien classés\n",
    "Il s’agit de l’indicateur le plus connu. On le nomme accuracy. Il est calculé à partir du rapport entre le nombre d’individus bien classés et le nombre total d’individus dans l’échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de bien classés pour le modèle RF : 1.000\n",
      "Pourcentage de bien classés pour le modèle kNN :0.856\n",
      "Pourcentage de bien classés pour le modèle naiveB :1.000\n",
      "Pourcentage de bien classés pour le modèle GBM :1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "accuracy_modele_rf = accuracy_score(y_test,y_predict_rf)\n",
    "accuracy_modele_knn = accuracy_score(y_test,y_predict_knn)\n",
    "accuracy_modele_nb = accuracy_score(y_test,y_predict_nb)\n",
    "accuracy_modele_gbm = accuracy_score(y_test,y_predict_gbm)\n",
    "\n",
    "print(\"Pourcentage de bien classés pour le modèle RF : %.3f\" %(accuracy_modele_rf))\n",
    "print(\"Pourcentage de bien classés pour le modèle kNN :%.3f\" %(accuracy_modele_knn))\n",
    "print(\"Pourcentage de bien classés pour le modèle naiveB :%.3f\" %(accuracy_modele_nb))\n",
    "print(\"Pourcentage de bien classés pour le modèle GBM :%.3f\" %(accuracy_modele_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel pour le modèle RF : 1.000\n",
      "Rappel pour le modèle kNN :0.117\n"
     ]
    }
   ],
   "source": [
    "recall_modele_rf=recall_score(y_test,y_predict_rf)\n",
    "recall_modele_knn=recall_score(y_test,y_predict_knn)\n",
    "print(\"Rappel pour le modèle RF : %.3f\" %(recall_modele_rf))\n",
    "print(\"Rappel pour le modèle kNN :%.3f\" %(recall_modele_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## La matrice de confusion\n",
    "Il s’agit d’un autre indicateur important pour juger de la qualité d’un modèle, il n’est pas défini par une seule valeur mais par une matrice dans laquelle on peut lire le croisement entre les valeurs observées et les valeurs prédites à partir du modèle. \n",
    "\n",
    "Pour calculer cette matrice, on pourra utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion pour le modèle RF :\n",
      "[[855   0]\n",
      " [  0 145]]\n",
      "Matrice de confusion pour le modèle kNN :\n",
      "[[839  16]\n",
      " [128  17]]\n",
      "Matrice de confusion pour le modèle NB :\n",
      "[[855   0]\n",
      " [  0 145]]\n",
      "Matrice de confusion pour le modèle GBM :\n",
      "[[855   0]\n",
      " [  0 145]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_rf=confusion_matrix(y_test,y_predict_rf)\n",
    "confusion_matrix_knn=confusion_matrix(y_test,y_predict_knn)\n",
    "confusion_matrix_nb=confusion_matrix(y_test,y_predict_nb)\n",
    "confusion_matrix_gbm=confusion_matrix(y_test,y_predict_gbm)\n",
    "\n",
    "print(\"Matrice de confusion pour le modèle RF :\",\n",
    "confusion_matrix_rf, sep=\"\\n\")\n",
    "print(\"Matrice de confusion pour le modèle kNN :\",\n",
    "confusion_matrix_knn, sep=\"\\n\")\n",
    "print(\"Matrice de confusion pour le modèle NB :\",\n",
    "confusion_matrix_nb, sep=\"\\n\")\n",
    "print(\"Matrice de confusion pour le modèle GBM :\",\n",
    "confusion_matrix_gbm, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Le rappel (recall), la précision et le f1-score\n",
    "\n",
    "Scikit-Learn possède des fonctions pour chacun de ces indicateurs, mais il peut\n",
    "être intéressant d’utiliser une autre fonction qui les affiche pour chaque classe :\n",
    "\n",
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport pour le modèle RF :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00       145\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Rapport pour le modèle RF :\",\n",
    "      classification_report(y_test,y_predict_rf) ,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport pour le modèle kNN :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       855\n",
      "           1       0.52      0.12      0.19       145\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.69      0.55      0.56      1000\n",
      "weighted avg       0.82      0.86      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Rapport pour le modèle kNN :\",\n",
    "      classification_report(y_test,y_predict_knn) ,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## L’aire sous la courbe ROC\n",
    "La courbe ROC est un indicateur important mais on préfère souvent une valeur plutôt\n",
    "qu’une courbe afin de comparer nos modèles. Pour cela, on utilise l’aire sous la courbe\n",
    "ROC (AUC). Cette aire est calculée directement à partir de la courbe ROC. Ainsi, un\n",
    "modèle aléatoire aura une AUC de 0.5 et un modèle parfait aura une AUC de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aire sous la courbe ROC pour le modèle RF : 1.0\n",
      "Aire sous la courbe ROC pour le modèle kNN : 0.6172897761645493\n",
      "Aire sous la courbe ROC pour le modèle NB : 1.0\n",
      "Aire sous la courbe ROC pour le modèle GBM : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_modele_rf=roc_auc_score(y_test, modele_rf.predict_proba(x_test)[:,1])\n",
    "auc_modele_knn=roc_auc_score(y_test,modele_knn.predict_proba(x_test)[:,1])\n",
    "auc_modele_nb=roc_auc_score(y_test,modele_nb.predict_proba(x_test)[:,1])\n",
    "auc_modele_gbm=roc_auc_score(y_test,modele_gbm.predict_proba(x_test)[:,1])\n",
    "\n",
    "print(\"Aire sous la courbe ROC pour le modèle RF :\" ,auc_modele_rf)\n",
    "print(\"Aire sous la courbe ROC pour le modèle kNN :\" ,auc_modele_knn)\n",
    "print(\"Aire sous la courbe ROC pour le modèle NB :\" ,auc_modele_nb)\n",
    "print(\"Aire sous la courbe ROC pour le modèle GBM :\" ,auc_modele_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## La validation croisée\n",
    "Jusqu’ici nous avons utilisé des indicateurs basés sur une seule occurrence de test. Ceci veut dire qu’on ne teste notre modèle que sur un seul échantillon.\n",
    "\n",
    "Une approche alternative souvent utilisée est la validation croisée. Celle-ci est en fait basée sur la répétition de l’estimation et de la validation sur des données différentes.\n",
    "\n",
    "Pour obtenir ce cv-score, on utilise :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC pour RF : 1.000 (+/- 0.000)\n",
      "AUC pour kNN : 0.587 (+/- 0.105)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_rf = cross_val_score(modele_rf, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "scores_knn = cross_val_score(modele_knn, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"AUC pour RF : %.3f (+/- %.3f)\"% (scores_rf.mean(), scores_rf.std() * 2))\n",
    "print(\"AUC pour kNN : %.3f (+/- %.3f)\"% (scores_knn.mean(),scores_knn.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## L’ajustement des hyperparamètres d’un modèle\n",
    "\n",
    "L’une des tâches du data scientist est de trouver le meilleur modèle possible. La\n",
    "plupart des modèles de machine learning ont des hyperparamètres. Il s’agit de paramètres\n",
    "du modèle qui sont définis en amont de l’ajustement.\n",
    "\n",
    "Scikit-Learn propose une classe GridSearchCV permettant d’implémenter cette\n",
    "recherche d’hyperparamètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On va donc devoir définir les hyperparamètres que l’on souhaite tester. Pour cela,\n",
    "on utilisera un dictionnaire d’hyperparamètres, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dico_param= {\"max_depth\":[3,5,7,10], \"n_estimators\":[10,50,100,1000]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On va encore utiliser l’accuracy pour valider notre modèle. Finalement, nous allons\n",
    "utiliser une validation croisée à cinq groupes pour valider les résultats.\n",
    "Le nouvel objet est le suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "recherche_hyper = GridSearchCV(RandomForestClassifier(), \n",
    "                               dico_param, \n",
    "                               scoring=\"accuracy\",cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Une fois qu’on a créé cet objet, on peut lui joindre les données afin d’estimer les\n",
    "meilleurs paramètres du modèle.\n",
    "\n",
    "Cette étape peut être très longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 5, 7, 10],\n",
       "                         'n_estimators': [10, 50, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recherche_hyper.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(recherche_hyper.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(recherche_hyper.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 10}</td>\n",
       "      <td>0.946595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>0.985599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.993099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 1000}</td>\n",
       "      <td>0.996100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 10}</td>\n",
       "      <td>0.988899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 10}</td>\n",
       "      <td>0.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 50}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 1000}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 1000}</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score\n",
       "0      {'max_depth': 3, 'n_estimators': 10}         0.946595\n",
       "1      {'max_depth': 3, 'n_estimators': 50}         0.985599\n",
       "2     {'max_depth': 3, 'n_estimators': 100}         0.993099\n",
       "3    {'max_depth': 3, 'n_estimators': 1000}         0.996100\n",
       "4      {'max_depth': 5, 'n_estimators': 10}         0.988899\n",
       "5      {'max_depth': 5, 'n_estimators': 50}         0.999400\n",
       "6     {'max_depth': 5, 'n_estimators': 100}         1.000000\n",
       "7    {'max_depth': 5, 'n_estimators': 1000}         1.000000\n",
       "8      {'max_depth': 7, 'n_estimators': 10}         0.999700\n",
       "9      {'max_depth': 7, 'n_estimators': 50}         1.000000\n",
       "10    {'max_depth': 7, 'n_estimators': 100}         1.000000\n",
       "11   {'max_depth': 7, 'n_estimators': 1000}         1.000000\n",
       "12    {'max_depth': 10, 'n_estimators': 10}         1.000000\n",
       "13    {'max_depth': 10, 'n_estimators': 50}         1.000000\n",
       "14   {'max_depth': 10, 'n_estimators': 100}         1.000000\n",
       "15  {'max_depth': 10, 'n_estimators': 1000}         1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(recherche_hyper.cv_results_)[[\"params\",\"mean_test_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La construction d’un pipeline de traitement\n",
    "\n",
    "Bien souvent vous allez être amené à enchaîner des traitements sur des données.\n",
    "On peut bien sûr développer son code de manière à suivre les étapes une à une mais il est souvent plus intéressant de créer des suites de traitements automatisées avec Scikit-Learn. \n",
    "\n",
    "Ces suites de traitements sont appelées pipeline. Ils simplifieront votre code et permettront de passer en production simplement.\n",
    "\n",
    "Ainsi, on va pouvoir faire une analyse en composantes principales suivies d’un\n",
    "algorithme de plus proches voisins directement dans un pipeline :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp=PCA(n_components=8)\n",
    "#knn=KNeighborsClassifier()\n",
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s4d-asus-14\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composantes = acp.fit_transform(x)\n",
    "rf.fit(composantes,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composantes_test = acp.transform(x)\n",
    "rf.predict(composantes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s4d-asus-14\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('acp',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=None,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipe2=Pipeline(steps=[(\"acp\",PCA()),(\"rf\",RandomForestClassifier())])\n",
    "pipe2.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On a ainsi enchaîné deux traitements. Si on cherche des sorties liées à chacune\n",
    "des étapes, on pourra le faire simplement. Par exemple, si l’objectif est d’extraire la part de variances expliquées par les composantes de l’analyse en composantes principales, on fera :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.85955067e-01, 3.25154733e-03, 2.78121524e-03, 2.70527664e-03,\n",
       "       1.91317470e-03, 1.68656685e-03, 4.30288237e-04, 4.22903707e-04,\n",
       "       4.03619953e-04, 2.34597638e-04, 1.98350089e-04, 8.91196877e-06,\n",
       "       6.41312160e-06, 1.84109579e-06, 1.34833141e-07, 7.39849334e-08,\n",
       "       1.78037265e-08, 8.81869864e-12, 8.70751746e-12, 8.37255932e-12,\n",
       "       8.10577314e-12])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.named_steps[\"acp\"].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trouver la meilleure combinaison d’hyperparamètres dans un pipeline\n",
    "\n",
    "Essayons de trouver la meilleure combinaison d’hyperparamètres dans un pipeline.\n",
    "Dans le cadre de cet exemple, nous utiliserons les SVM (support vector machines,\n",
    "également appelés séparateurs à vaste marge ou machines à vecteurs de support).\n",
    "Ce sont des méthodes assez complexes dans leur principe mais simples dans leur\n",
    "mise en oeuvre.\n",
    "\n",
    "Les hyperparamètres d’un modèle de SVM sont assez nombreux. Les plus importants\n",
    "étant le noyau choisi (linéaire, polynomial, sigmoïd, RBF…), les paramètres de\n",
    "ces noyaux (le degré pour le cas polynomiale, gamma…) et le C pour la marge floue.\n",
    "\n",
    "Dans notre exemple, on utilisera la fonction make_pipeline qui est équivalente\n",
    "à la classe précédente avec quelques simplifications :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# construction du pipeline basé sur deux approches\n",
    "mon_pipe=make_pipeline(PCA(), SVC(probability=True))\n",
    "\n",
    "# construction du dictionnaire des paramètres\n",
    "# (attention utilisation de __)\n",
    "param_grid = dict(pca__n_components=[5, 10, x_train.shape[1]],\n",
    "                  svc__C= [1, 10, 100, 1000],\n",
    "                  svc__kernel= ['sigmoid', 'rbf'],\n",
    "                  svc__gamma= [0.001, 0.0001])\n",
    "\n",
    "# on construit l’objet GridSearch et on estime les hyper-paramètres\n",
    "# par validation croisée\n",
    "grid_search_mon_pipe = GridSearchCV(mon_pipe, param_grid = param_grid, scoring = \"roc_auc\", cv = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_mon_pipe.fit(x_train,y_train)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 21,\n",
       " 'svc__C': 1,\n",
       " 'svc__gamma': 0.0001,\n",
       " 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la meilleure combinaisons de paramètres est :\n",
    "grid_search_mon_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6703928791444584"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_mon_pipe.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Les meilleurs hyperparamètres obtenus en utilisant l’aire sous la courbe ROC sont\n",
    "la combinaison C = 10, gamma = 0.0001, un noyau RBF pour les SVM et dix composantes\n",
    "pour notre analyse en composantes principales.\n",
    "\n",
    "Dans ce code, on définit les hyperparamètres associés à une méthode du pipeline\n",
    "avec un double underscore : __.\n",
    "\n",
    "L’utilisation des pipelines de Scikit-Learn va devenir rapidement une étape cruciale\n",
    "de vos développements en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Passer en production votre modèle d’apprentissage supervisé\n",
    "\n",
    "### Persistance de modèle avec Scikit-Learn\n",
    "\n",
    "Python possède plusieurs outils pour la persistance d’objets, c’est-à-dire pour stocker\n",
    "des objets dans des fichiers. Les objets de Scikit-Learn sont aussi dans cette\n",
    "situation. On utilise un format pickle qui aura l’extension .pkl.\n",
    "\n",
    "Par exemple, si nous voulons sauvegarder le dernier pipeline de traitement, nous\n",
    "allons utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/modele_grid_pipe.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid_search_mon_pipe, './data/modele_grid_pipe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une fois ce modèle stocké, on peut très bien le réutiliser dans un autre cadre. Si\n",
    "nous créons un nouveau notebook, nous allons utiliser :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "grid_search_mon_pipe = joblib.load('./data/modele_grid_pipe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut ensuite appliquer le modèle avec tous les paramètres qui ont été appris :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "grid_search_mon_pipe.predict(x_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "L’utilisation d’un fichier Pickle dans un notebook est une technique assez simple et courante."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
